# ğŸš€ My Application - Helm & ArgoCD Deployment

## ğŸ‘¨â€ğŸ’» **Author**

**Bonaventure Simeon**  
ğŸ“§ Email: [contact@bonaventure.org.ng](mailto:contact@bonaventure.org.ng)  
ğŸ“± Phone: [+234 (812) 222 5406](tel:+2348122225406)

---

## ğŸ¯ **Overview**

This is a modern application deployment platform using Helm charts and ArgoCD for GitOps automation. The platform provides complete deployment automation, health monitoring, and infrastructure management with integrated CI/CD pipelines and cluster management capabilities.

---

## ğŸŒŸ **Quick Start - One Command Deployment**

### **ğŸš€ Helm & ArgoCD Deployment (Recommended)**
```bash
# Clone and deploy with Helm and ArgoCD
git clone <your-repository-url>
cd my-app
chmod +x scripts/deploy.sh
./scripts/deploy.sh
```

**ğŸ‰ Your application will be live at:**
- **â˜¸ï¸ Application**: http://your-domain.com (Production)
- **ğŸ”„ ArgoCD**: http://localhost:8080 (GitOps Management)

For detailed setup instructions, see [QUICK_START.md](QUICK_START.md).

---

## ğŸ› ï¸ **Deployment Options**

The deployment script provides comprehensive deployment and management capabilities:

```bash
# Full deployment with ArgoCD and application (default)
./scripts/deploy.sh

# Choose from the following options:
# 1. Install ArgoCD and deploy application
# 2. Deploy application only (ArgoCD already installed)
# 3. Build and push Docker image only
```

### **ğŸ”§ What the Deployment Script Does:**

#### **Option 1: Full Deployment**
- âœ… Installs ArgoCD server
- âœ… Builds and pushes Docker image
- âœ… Deploys Helm chart with dependencies
- âœ… Sets up ArgoCD application for GitOps
- âœ… Verifies deployment health

#### **Option 2: Application Only**
- âœ… Builds and pushes Docker image
- âœ… Deploys Helm chart with dependencies
- âœ… Sets up ArgoCD application for GitOps
- âœ… Verifies deployment health

#### **Option 3: Image Only**
- âœ… Builds and pushes Docker image
- âœ… Updates image tags in configuration

---

## ğŸ“ **Project Structure**

```
my-app/
â”œâ”€â”€ app/                    # Application source code
â”œâ”€â”€ helm-chart/            # Helm chart for Kubernetes deployment
â”‚   â”œâ”€â”€ templates/         # Kubernetes manifests
â”‚   â”œâ”€â”€ Chart.yaml         # Chart metadata
â”‚   â””â”€â”€ values.yaml        # Configuration values
â”œâ”€â”€ argocd/               # ArgoCD application manifests
â”œâ”€â”€ scripts/              # Deployment and utility scripts
â”œâ”€â”€ .github/workflows/    # CI/CD pipelines
â”œâ”€â”€ Dockerfile            # Container image definition
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

## ğŸš€ **Deployment Flow Diagram**

```mermaid
flowchart TD
    A[ğŸš€ Start Deployment] --> B{Check Environment}
    B -->|Containerized| C[âš ï¸ Show Alternatives]
    B -->|VM/Bare Metal| D[âœ… Proceed with Deployment]
    
    D --> E[ğŸ“¦ Install Tools]
    E --> F[Docker]
    E --> G[kubectl]
    E --> H[Kind]
    E --> I[Helm]
    E --> J[ArgoCD CLI]
    
    F --> K[ğŸ§¹ Cleanup Existing]
    G --> K
    H --> K
    I --> K
    J --> K
    
    K --> L[â˜¸ï¸ Create Cluster]
    L --> M[Control Plane Node]
    L --> N[Worker Node 1]
    L --> O[Worker Node 2]
    
    M --> P[ğŸ“¦ Deploy Application]
    N --> P
    O --> P
    
    P --> Q[ğŸ”„ Install ArgoCD]
    Q --> R[ğŸ”— Setup Port Forwarding]
    R --> S[âœ… Verify Deployment]
    S --> T[ğŸ‰ Deployment Complete]
    
    C --> U[ğŸ“‹ Alternative Options]
    U --> V[1. VM/Bare Metal]
    U --> W[2. Cloud Kubernetes]
    U --> X[3. Local Kubernetes]
    U --> Y[4. Manual Docker]
    
    style A fill:#e1f5fe
    style T fill:#c8e6c9
    style C fill:#fff3e0
    style U fill:#f3e5f5
```

---

## ğŸ”§ **Troubleshooting Flow Diagram**

```mermaid
flowchart TD
    A[ğŸ”§ Start Troubleshooting] --> B{Check kubectl}
    B -->|Not Available| C[ğŸ“¦ Install kubectl]
    B -->|Available| D[ğŸ” Check Cluster]
    
    C --> D
    D -->|Cannot Connect| E[âŒ Cluster Issue]
    D -->|Connected| F[ğŸ“Š Check Resources]
    
    E --> G[ğŸ”„ Recreate Cluster]
    G --> H[âœ… Cluster Ready]
    
    F --> I[ğŸ“‹ Check Namespaces]
    I --> J{student-tracker exists?}
    J -->|No| K[ğŸ“¦ Create Namespace]
    J -->|Yes| L[ğŸ” Check Deployments]
    
    K --> L
    L --> M{Deployment exists?}
    M -->|No| N[ğŸ“¦ Redeploy Application]
    M -->|Yes| O[ğŸ” Check Pods]
    
    N --> O
    O --> P{Pods Running?}
    P -->|No| Q[ğŸ“‹ Check Pod Logs]
    P -->|Yes| R[ğŸ” Check Services]
    
    Q --> S[ğŸ”§ Fix Pod Issues]
    S --> T[ğŸ”„ Restart Pods]
    T --> R
    
    R --> U{Services OK?}
    U -->|No| V[ğŸ”§ Fix Service Issues]
    U -->|Yes| W[ğŸ” Check Endpoints]
    
    V --> W
    W --> X{Endpoints OK?}
    X -->|No| Y[ğŸ”§ Fix Endpoint Issues]
    X -->|Yes| Z[âœ… Troubleshooting Complete]
    
    Y --> Z
    
    style A fill:#e1f5fe
    style Z fill:#c8e6c9
    style E fill:#ffcdd2
    style G fill:#fff3e0
```

---

## ğŸ—ï¸ **System Architecture**

### ğŸ¯ **High-Level Architecture**

```mermaid
graph TB
    subgraph "ğŸŒ Internet"
        User[ğŸ‘¤ End Users]
        Admin[ğŸ‘¨â€ğŸ’¼ Administrators]
    end
    
    subgraph "ğŸ–¥ï¸ Production Server (18.206.89.183)"
        subgraph "ğŸŒ Load Balancer Layer"
            LB[ğŸŒ Load Balancer<br/>Port 80/443]
        end
        
        subgraph "ğŸ³ Docker Compose Stack"
            Nginx[ğŸŒ Nginx<br/>Port 80<br/>Reverse Proxy]
            
            subgraph "ğŸ“ Application Layer"
                App[ğŸ“ Student Tracker<br/>FastAPI<br/>Port 8011]
                API[ğŸ“– API Documentation<br/>Swagger UI<br/>Port 8011/docs]
            end
            
            subgraph "ğŸ—„ï¸ Data Layer"
                DB[(ğŸ—„ï¸ PostgreSQL<br/>Port 5432<br/>Primary Database)]
                Cache[(ğŸ“¦ Redis<br/>Port 6379<br/>Session Cache)]
            end
            
            subgraph "ğŸ“Š Monitoring Stack"
                Prom[ğŸ“ˆ Prometheus<br/>Port 9090<br/>Metrics Collection]
                Graf[ğŸ“Š Grafana<br/>Port 3000<br/>Dashboards]
                Admin[ğŸ› ï¸ Adminer<br/>Port 8080<br/>DB Admin]
            end
        end
        
        subgraph "â˜¸ï¸ Kubernetes Cluster"
            subgraph "ğŸ¯ Control Plane"
                CP[â˜¸ï¸ Control Plane<br/>Node 1]
            end
            
            subgraph "âš¡ Worker Nodes"
                W1[âš¡ Worker Node 1]
                W2[âš¡ Worker Node 2]
            end
            
            subgraph "ğŸ”„ GitOps Layer"
                Argo[ğŸ”„ ArgoCD<br/>Port 30080<br/>GitOps Controller]
                App2[ğŸ“ NativeSeries<br/>Port 30012<br/>K8s Deployment]
            end
        end
    end
    
    User --> LB
    Admin --> LB
    LB --> Nginx
    LB --> Argo
    
    Nginx --> App
    App --> API
    App --> DB
    App --> Cache
    App --> Prom
    Prom --> Graf
    Admin --> DB
    
    Argo --> App2
    App2 --> W1
    App2 --> W2
    
    style User fill:#e1f5fe
    style Admin fill:#e1f5fe
    style App fill:#c8e6c9
    style App2 fill:#c8e6c9
    style DB fill:#fff3e0
    style Cache fill:#f3e5f5
    style Nginx fill:#e8f5e8
    style Prom fill:#ffe0b2
    style Graf fill:#fce4ec
    style Admin fill:#e0f2f1
    style Argo fill:#e8eaf6
    style CP fill:#f3e5f5
    style W1 fill:#e0f2f1
    style W2 fill:#e0f2f1
```

### ğŸ³ **Container Architecture**

```mermaid
graph LR
    subgraph "ğŸ³ Docker Compose Services"
        subgraph "ğŸ“ Application Services"
            ST[ğŸ“ student-tracker<br/>Port 8011<br/>FastAPI App]
            API[ğŸ“– API Docs<br/>Swagger UI<br/>Auto-generated]
        end
        
        subgraph "ğŸ—„ï¸ Data Services"
            PG[ğŸ—„ï¸ postgres<br/>Port 5432<br/>Primary Database]
            RD[ğŸ“¦ redis<br/>Port 6379<br/>Session Cache]
        end
        
        subgraph "ğŸŒ Network Services"
            NG[ğŸŒ nginx<br/>Port 80<br/>Reverse Proxy<br/>Load Balancer]
        end
        
        subgraph "ğŸ“Š Monitoring Services"
            PM[ğŸ“ˆ prometheus<br/>Port 9090<br/>Metrics Collection<br/>Time Series DB]
            GF[ğŸ“Š grafana<br/>Port 3000<br/>Dashboards<br/>Visualization]
            AD[ğŸ› ï¸ adminer<br/>Port 8080<br/>Database Admin<br/>Web Interface]
        end
    end
    
    subgraph "â˜¸ï¸ Kubernetes Services"
        subgraph "ğŸ”„ GitOps"
            AR[ğŸ”„ ArgoCD<br/>Port 30080<br/>GitOps Controller<br/>CD Pipeline]
        end
        
        subgraph "ğŸ¯ Application"
            NS[ğŸ“ NativeSeries<br/>Port 30012<br/>K8s Deployment<br/>Scalable App]
        end
    end
    
    NG --> ST
    ST --> API
    ST --> PG
    ST --> RD
    ST --> PM
    PM --> GF
    AD --> PG
    
    AR --> NS
    
    style ST fill:#c8e6c9
    style API fill:#c8e6c9
    style PG fill:#fff3e0
    style RD fill:#f3e5f5
    style NG fill:#e8f5e8
    style PM fill:#ffe0b2
    style GF fill:#fce4ec
    style AD fill:#e0f2f1
    style AR fill:#e8eaf6
    style NS fill:#c8e6c9
```

### ğŸ”„ **GitOps Workflow**

```mermaid
graph LR
    subgraph "ğŸ“ Development"
        Dev[ğŸ‘¨â€ğŸ’» Developer]
        Code[ğŸ’» Code Changes]
        Git[ğŸ“š Git Repository]
    end
    
    subgraph "ğŸ”„ CI/CD Pipeline"
        CI[âš™ï¸ CI Pipeline]
        Build[ğŸ”¨ Build Image]
        Push[ğŸ“¤ Push to Registry]
    end
    
    subgraph "â˜¸ï¸ Kubernetes Cluster"
        Argo[ğŸ”„ ArgoCD]
        App[ğŸ“ NativeSeries App]
        DB[(ğŸ—„ï¸ Database)]
        Cache[(ğŸ“¦ Cache)]
    end
    
    subgraph "ğŸ“Š Monitoring"
        Prom[ğŸ“ˆ Prometheus]
        Graf[ğŸ“Š Grafana]
        Alert[ğŸš¨ Alerts]
    end
    
    Dev --> Code
    Code --> Git
    Git --> CI
    CI --> Build
    Build --> Push
    Push --> Argo
    Argo --> App
    App --> DB
    App --> Cache
    App --> Prom
    Prom --> Graf
    Graf --> Alert
    
    style Dev fill:#e1f5fe
    style Argo fill:#e8eaf6
    style App fill:#c8e6c9
    style DB fill:#fff3e0
    style Cache fill:#f3e5f5
    style Prom fill:#ffe0b2
    style Graf fill:#fce4ec
```

### ğŸ“Š **Data Flow Architecture**

```mermaid
graph TB
    subgraph "ğŸŒ External Requests"
        User[ğŸ‘¤ User Request]
        API[ğŸ“– API Request]
        Health[ğŸ©º Health Check]
    end
    
    subgraph "ğŸŒ Load Balancer"
        LB[ğŸŒ Nginx Load Balancer]
    end
    
    subgraph "ğŸ“ Application Layer"
        FastAPI[ğŸ“ FastAPI Application]
        Auth[ğŸ” Authentication]
        Cache[ğŸ“¦ Redis Cache]
    end
    
    subgraph "ğŸ—„ï¸ Data Layer"
        DB[(ğŸ—„ï¸ PostgreSQL)]
        Backup[(ğŸ’¾ Database Backup)]
    end
    
    subgraph "ğŸ“Š Monitoring Layer"
        Metrics[ğŸ“ˆ Application Metrics]
        Logs[ğŸ“ Application Logs]
        Prom[ğŸ“Š Prometheus]
        Graf[ğŸ“ˆ Grafana]
    end
    
    User --> LB
    API --> LB
    Health --> LB
    
    LB --> FastAPI
    FastAPI --> Auth
    FastAPI --> Cache
    FastAPI --> DB
    FastAPI --> Metrics
    FastAPI --> Logs
    
    Cache --> DB
    DB --> Backup
    
    Metrics --> Prom
    Logs --> Prom
    Prom --> Graf
    
    style User fill:#e1f5fe
    style FastAPI fill:#c8e6c9
    style DB fill:#fff3e0
    style Cache fill:#f3e5f5
    style Prom fill:#ffe0b2
    style Graf fill:#fce4ec
```

### ğŸ” **Monitoring & Observability**

```mermaid
graph TB
    subgraph "ğŸ“ Application"
        App[ğŸ“ NativeSeries App]
        Health[ğŸ©º Health Endpoint]
        Metrics[ğŸ“Š Metrics Endpoint]
    end
    
    subgraph "ğŸ“ˆ Metrics Collection"
        Prom[ğŸ“ˆ Prometheus Server]
        Scrape[ğŸ” Scraping Jobs]
        Storage[(ğŸ’¾ Time Series DB)]
    end
    
    subgraph "ğŸ“Š Visualization"
        Graf[ğŸ“Š Grafana]
        Dash[ğŸ“‹ Dashboards]
        Alert[ğŸš¨ Alerting]
    end
    
    subgraph "ğŸ”§ Infrastructure"
        K8s[â˜¸ï¸ Kubernetes]
        Nodes[ğŸ–¥ï¸ Cluster Nodes]
        Pods[ğŸ“¦ Application Pods]
    end
    
    subgraph "ğŸ“ Logging"
        Logs[ğŸ“ Application Logs]
        K8sLogs[â˜¸ï¸ K8s Logs]
        SysLogs[ğŸ–¥ï¸ System Logs]
    end
    
    App --> Health
    App --> Metrics
    Metrics --> Prom
    Prom --> Scrape
    Scrape --> Storage
    Storage --> Graf
    Graf --> Dash
    Graf --> Alert
    
    K8s --> Nodes
    Nodes --> Pods
    Pods --> App
    
    App --> Logs
    K8s --> K8sLogs
    Nodes --> SysLogs
    
    style App fill:#c8e6c9
    style Prom fill:#ffe0b2
    style Graf fill:#fce4ec
    style K8s fill:#e8eaf6
    style Logs fill:#e0f2f1
```

### ğŸŒ **Network Topology**

```mermaid
graph TB
    subgraph "ğŸŒ Internet"
        Internet[ğŸŒ Internet Traffic]
    end
    
    subgraph "ğŸ–¥ï¸ Production Server"
        subgraph "ğŸŒ Network Layer"
            Firewall[ğŸ”¥ Firewall<br/>Ports: 80, 443, 30012, 30080]
            LoadBalancer[âš–ï¸ Load Balancer<br/>Port 80/443]
        end
        
        subgraph "ğŸ³ Container Network"
            Nginx[ğŸŒ Nginx<br/>Port 80<br/>Reverse Proxy]
            App[ğŸ“ FastAPI App<br/>Port 8011]
            Argo[ğŸ”„ ArgoCD<br/>Port 30080]
        end
        
        subgraph "ğŸ—„ï¸ Database Network"
            DB[(ğŸ—„ï¸ PostgreSQL<br/>Port 5432)]
            Cache[(ğŸ“¦ Redis<br/>Port 6379)]
        end
        
        subgraph "ğŸ“Š Monitoring Network"
            Prom[ğŸ“ˆ Prometheus<br/>Port 9090]
            Graf[ğŸ“Š Grafana<br/>Port 3000]
            Admin[ğŸ› ï¸ Adminer<br/>Port 8080]
        end
    end
    
    Internet --> Firewall
    Firewall --> LoadBalancer
    LoadBalancer --> Nginx
    LoadBalancer --> Argo
    
    Nginx --> App
    App --> DB
    App --> Cache
    App --> Prom
    Prom --> Graf
    Admin --> DB
    
    style Internet fill:#e1f5fe
    style Firewall fill:#ffcdd2
    style LoadBalancer fill:#fff3e0
    style App fill:#c8e6c9
    style DB fill:#fff3e0
    style Cache fill:#f3e5f5
    style Prom fill:#ffe0b2
    style Graf fill:#fce4ec
```

### ğŸ”§ **Component Interaction**

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant LB as ğŸŒ Load Balancer
    participant N as ğŸŒ Nginx
    participant A as ğŸ“ FastAPI App
    participant C as ğŸ“¦ Redis Cache
    participant D as ğŸ—„ï¸ PostgreSQL
    participant P as ğŸ“ˆ Prometheus
    participant G as ğŸ“Š Grafana
    
    U->>LB: HTTP Request
    LB->>N: Forward Request
    N->>A: Proxy to App
    
    A->>C: Check Cache
    alt Cache Hit
        C->>A: Return Cached Data
    else Cache Miss
        A->>D: Query Database
        D->>A: Return Data
        A->>C: Update Cache
    end
    
    A->>A: Process Request
    A->>P: Send Metrics
    P->>G: Store Metrics
    
    A->>N: Return Response
    N->>LB: Forward Response
    LB->>U: HTTP Response
    
    Note over A,P: Continuous Monitoring
    loop Every 15s
        P->>A: Scrape Metrics
        A->>P: Application Metrics
        P->>G: Update Dashboards
    end
```

### ğŸ—ï¸ **Infrastructure Layers**

```mermaid
graph TB
    subgraph "ğŸ¯ Application Layer"
        FastAPI[ğŸ“ FastAPI Application]
        API[ğŸ“– API Documentation]
        Health[ğŸ©º Health Checks]
    end
    
    subgraph "ğŸ”„ Orchestration Layer"
        K8s[â˜¸ï¸ Kubernetes]
        Argo[ğŸ”„ ArgoCD]
        Helm[ğŸ“¦ Helm Charts]
    end
    
    subgraph "ğŸ³ Container Layer"
        Docker[ğŸ³ Docker Engine]
        Images[ğŸ“¦ Container Images]
        Registry[ğŸ“š Image Registry]
    end
    
    subgraph "ğŸ–¥ï¸ Infrastructure Layer"
        VM[ğŸ–¥ï¸ Virtual Machine]
        Storage[ğŸ’¾ Storage]
        Network[ğŸŒ Network]
    end
    
    subgraph "â˜ï¸ Cloud Layer"
        Cloud[â˜ï¸ Cloud Provider]
        Security[ğŸ”’ Security Groups]
        LoadBalancer[âš–ï¸ Load Balancer]
    end
    
    FastAPI --> K8s
    API --> K8s
    Health --> K8s
    
    K8s --> Argo
    K8s --> Helm
    
    Argo --> Docker
    Helm --> Docker
    
    Docker --> Images
    Images --> Registry
    
    Docker --> VM
    VM --> Storage
    VM --> Network
    
    VM --> Cloud
    Network --> Security
    Network --> LoadBalancer
    
    style FastAPI fill:#c8e6c9
    style K8s fill:#e8eaf6
    style Docker fill:#e3f2fd
    style VM fill:#f3e5f5
    style Cloud fill:#e0f2f1
```

### ğŸ“Š **Health Check Flow**

```mermaid
graph TD
    A[ğŸ¥ Start Health Check] --> B[ğŸ” Check Docker]
    B --> C{Docker Running?}
    C -->|No| D[âŒ Docker Issue]
    C -->|Yes| E[âœ… Docker OK]
    
    E --> F[ğŸ” Check Kubernetes]
    F --> G{K8s Accessible?}
    G -->|No| H[âŒ K8s Issue]
    G -->|Yes| I[âœ… K8s OK]
    
    I --> J[ğŸ” Check ArgoCD]
    J --> K{ArgoCD Running?}
    K -->|No| L[âŒ ArgoCD Issue]
    K -->|Yes| M[âœ… ArgoCD OK]
    
    M --> N[ğŸ” Check Network]
    N --> O{Network OK?}
    O -->|No| P[âŒ Network Issue]
    O -->|Yes| Q[âœ… Network OK]
    
    Q --> R[ğŸ” Check Endpoints]
    R --> S{Endpoints Responding?}
    S -->|No| T[âŒ Endpoint Issue]
    S -->|Yes| U[âœ… Endpoints OK]
    
    U --> V[ğŸ” Check Database]
    V --> W{Database OK?}
    W -->|No| X[âŒ Database Issue]
    W -->|Yes| Y[âœ… Database OK]
    
    Y --> Z[ğŸ” Check Resources]
    Z --> AA{Resources OK?}
    AA -->|No| BB[âŒ Resource Issue]
    AA -->|Yes| CC[âœ… Resources OK]
    
    CC --> DD[ğŸ“Š Generate Report]
    DD --> EE[ğŸ‰ Health Check Complete]
    
    style A fill:#e1f5fe
    style EE fill:#c8e6c9
    style D fill:#ffcdd2
    style H fill:#ffcdd2
    style L fill:#ffcdd2
    style P fill:#ffcdd2
    style T fill:#ffcdd2
    style X fill:#ffcdd2
    style BB fill:#ffcdd2
```

---

## ğŸŒ **Production Access Points**

| Service | Production URL | Status | Purpose | Credentials |
|---------|----------------|--------|---------|-------------|
| â˜¸ï¸ **Kubernetes App** | [http://18.206.89.183:30012](http://18.206.89.183:30012) | âœ… **LIVE** | Production/GitOps | - |
| ğŸ”„ **ArgoCD UI** | [http://18.206.89.183:30080](http://18.206.89.183:30080) | âœ… **LIVE** | GitOps Management | admin/(auto-generated) |
| ğŸ“– **API Documentation** | [http://18.206.89.183:8011/docs](http://18.206.89.183:8011/docs) | âœ… **LIVE** | Interactive Swagger UI | - |
| ğŸ©º **Health Check** | [http://18.206.89.183:8011/health](http://18.206.89.183:8011/health) | âœ… **LIVE** | System Health Status | - |
| ğŸ“Š **Metrics** | [http://18.206.89.183:8011/metrics](http://18.206.89.183:8011/metrics) | âœ… **LIVE** | Prometheus Metrics | - |
| ğŸŒ **Nginx Proxy** | [http://18.206.89.183:80](http://18.206.89.183:80) | âœ… **LIVE** | Load Balancer | - |
| ğŸ“ˆ **Grafana** | [http://18.206.89.183:3000](http://18.206.89.183:3000) | âœ… **LIVE** | Monitoring Dashboards | admin/admin123 |
| ğŸ“Š **Prometheus** | [http://18.206.89.183:9090](http://18.206.89.183:9090) | âœ… **LIVE** | Metrics Collection | - |
| ğŸ—„ï¸ **Database Admin** | [http://18.206.89.183:8080](http://18.206.89.183:8080) | âœ… **LIVE** | Database Admin Interface | student_user/student_pass |

---

## ğŸš€ **Deployment Options**

### ğŸ¯ **Complete Deployment (Kubernetes + ArgoCD)**

```bash
# Complete automated deployment with all tools and fixes
sudo ./deploy-unified.sh
```

**âœ… What this does:**
- Installs all required tools (Docker, kubectl, Kind, Helm, ArgoCD)
- Creates Kubernetes cluster with worker nodes (port 30012)
- Installs ArgoCD for GitOps (port 30080)
- Sets up port forwarding for ArgoCD UI
- Verifies all services are healthy
- **Includes all fixes**: Port conflicts, deployment timeouts, naming consistency
- **Perfect for**: Production, GitOps, learning Kubernetes
- **Time**: ~10-15 minutes
- **Requirements**: 8GB+ RAM, 20GB+ disk space

### ğŸ¥ **Health Monitoring**

```bash
# Comprehensive health check
sudo ./deploy-unified.sh --health-check
```

**âœ… What this does:**
- Verifies Kubernetes deployment status
- Monitors ArgoCD application health
- Tests network connectivity
- Validates database connectivity
- Monitors resource usage
- Provides detailed health report

### ğŸ”§ **Troubleshooting**

```bash
# Troubleshoot deployment issues
sudo ./deploy-unified.sh --troubleshoot
```

**âœ… What this does:**
- Diagnoses deployment problems
- Checks cluster connectivity
- Verifies resource status
- Offers repair options
- Provides detailed diagnostics

### ğŸ”„ **Cluster Management**

```bash
# Update cluster with worker nodes
sudo ./deploy-unified.sh --update-cluster
```

**âœ… What this does:**
- Creates cluster with worker nodes
- Improves resource distribution
- Enhances reliability
- Redeploys application
- Updates ArgoCD configuration

### ğŸ§¹ **Cleanup**

```bash
# Complete cleanup of all resources
sudo ./deploy-unified.sh --cleanup
```

**âœ… What this does:**
- Stops and removes all Docker containers
- Cleans up Docker images and volumes
- Removes Kubernetes cluster
- Deletes ArgoCD and applications
- Cleans temporary files and logs

---

## ğŸ› ï¸ **Technology Stack**

### ğŸ“ **Application Stack**

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Backend** | FastAPI | Latest | REST API Framework |
| **Database** | PostgreSQL | 15+ | Primary Database |
| **Cache** | Redis | 7+ | Session & Cache Store |
| **Frontend** | HTML/CSS/JS | - | Web Interface |
| **API Docs** | Swagger UI | Auto | Interactive Documentation |

### ğŸ³ **Container & Orchestration**

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Containerization** | Docker | 25.0+ | Application Packaging |
| **Orchestration** | Kubernetes | 1.33+ | Container Orchestration |
| **Local K8s** | Kind | 0.20+ | Local Kubernetes Cluster |
| **Package Manager** | Helm | 3.12+ | Kubernetes Package Manager |
| **GitOps** | ArgoCD | 2.8+ | Continuous Deployment |

### ğŸ“Š **Monitoring & Observability**

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Metrics** | Prometheus | 2.45+ | Metrics Collection |
| **Visualization** | Grafana | 10.0+ | Dashboards & Alerts |
| **Database Admin** | Adminer | 4.8+ | Database Management |
| **Load Balancer** | Nginx | 1.25+ | Reverse Proxy |

---

## ğŸ”§ **Troubleshooting Guide**

### ğŸš¨ **Common Issues & Solutions**

#### **1. Deployment Not Found Error**
```bash
Error from server (NotFound): deployments.apps "nativeseries" not found
```

**Solution:**
```bash
# Run troubleshooting
sudo ./deploy-unified.sh --troubleshoot

# Or redeploy completely
sudo ./deploy-unified.sh --update-cluster
```

#### **2. Cluster Connectivity Issues**
```bash
Cannot connect to Kubernetes cluster
```

**Solution:**
```bash
# Check cluster status
kubectl cluster-info

# Recreate cluster if needed
sudo ./deploy-unified.sh --update-cluster
```

#### **3. Application Not Responding**
```bash
Application endpoints not responding
```

**Solution:**
```bash
# Check application health
sudo ./deploy-unified.sh --health-check

# Check pod status
kubectl get pods -n student-tracker

# Check logs
kubectl logs -l app.kubernetes.io/name=nativeseries -n student-tracker
```

#### **4. Port Conflicts**
```bash
Port already in use
```

**Solution:**
```bash
# Clean up and redeploy
sudo ./deploy-unified.sh --cleanup
sudo ./deploy-unified.sh
```

### ğŸ” **Manual Troubleshooting Commands**

#### **Check Cluster Status**
```bash
# Check if kubectl is available
which kubectl

# Check cluster connectivity
kubectl cluster-info

# Check nodes
kubectl get nodes -o wide

# Check all resources
kubectl get all --all-namespaces
```

#### **Check Deployment Status**
```bash
# Check namespaces
kubectl get namespaces

# Check if student-tracker namespace exists
kubectl get namespace student-tracker

# Check deployments in student-tracker namespace
kubectl get deployments -n student-tracker

# Check pods in student-tracker namespace
kubectl get pods -n student-tracker

# Check services in student-tracker namespace
kubectl get services -n student-tracker
```

#### **Check Helm Releases**
```bash
# Check if Helm is installed
which helm

# List Helm releases
helm list --all-namespaces

# Check specific release
helm status nativeseries -n student-tracker
```

#### **Check Application Logs**
```bash
# Check pod logs
kubectl logs -l app.kubernetes.io/name=nativeseries -n student-tracker

# Check pod events
kubectl describe pods -n student-tracker

# Check service events
kubectl describe service nativeseries -n student-tracker
```

### ğŸ¯ **Expected Results After Fix**

After running the fix scripts, you should see:

1. **âœ… Cluster with 3 nodes** (1 control-plane + 2 workers)
2. **âœ… NativeSeries deployment running** in student-tracker namespace
3. **âœ… Application accessible** on port 30012
4. **âœ… Health endpoints responding** at http://localhost:30012/health

### ğŸ” **Verification Commands**

After fixing the deployment, verify with:

```bash
# Check cluster nodes
kubectl get nodes -o wide

# Check deployment status
kubectl get deployments -n student-tracker

# Check pod status
kubectl get pods -n student-tracker -o wide

# Check service endpoints
kubectl get endpoints -n student-tracker

# Test application health
curl http://localhost:30012/health

# Check application logs
kubectl logs -l app.kubernetes.io/name=nativeseries -n student-tracker
```

---

## ğŸ“‹ **Cluster Configuration**

### **Current Configuration (Single Node)**
```yaml
apiVersion: kind.x-k8s.io/v1alpha4
kind: Cluster
name: nativeseries
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30012
    hostPort: 30012
    protocol: TCP
  - containerPort: 30080
    hostPort: 30080
    protocol: TCP
```

### **Updated Configuration (With Worker Nodes)**
```yaml
apiVersion: kind.x-k8s.io/v1alpha4
kind: Cluster
name: nativeseries
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30012
    hostPort: 30012
    protocol: TCP
  - containerPort: 30080
    hostPort: 30080
    protocol: TCP
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  - |
    kind: KubeletConfiguration
    failSwapOn: false
- role: worker
  kubeadmConfigPatches:
  - |
    kind: KubeletConfiguration
    failSwapOn: false
- role: worker
  kubeadmConfigPatches:
  - |
    kind: KubeletConfiguration
    failSwapOn: false
```

---

## ğŸš€ **Quick Fix Commands**

For immediate resolution, run these commands in sequence:

```bash
# 1. Update cluster configuration and recreate with worker nodes
sudo ./deploy-unified.sh --update-cluster

# 2. Or troubleshoot existing deployment
sudo ./deploy-unified.sh --troubleshoot

# 3. Verify the fix
sudo ./deploy-unified.sh --health-check
```

---

## ğŸ“ **Support**

If issues persist after following this guide:

1. Check the logs: `kubectl logs -l app.kubernetes.io/name=nativeseries -n student-tracker`
2. Check pod events: `kubectl describe pods -n student-tracker`
3. Check service events: `kubectl describe service nativeseries -n student-tracker`
4. Run the comprehensive health check: `sudo ./deploy-unified.sh --health-check`

---

## ğŸ‰ **Success Indicators**

You'll know the fix was successful when:

- âœ… `kubectl get nodes` shows 3 nodes
- âœ… `kubectl get deployments -n student-tracker` shows nativeseries deployment
- âœ… `kubectl get pods -n student-tracker` shows running pods
- âœ… `curl http://localhost:30012/health` returns a successful response
- âœ… Health check script shows green status indicators

---

## ğŸ“š **Documentation**

### **ğŸ“– Deployment Guides**
- **[QUICK_START.md](QUICK_START.md)** - Get started in 10 minutes
- **[HELM_ARGOCD_DEPLOYMENT.md](HELM_ARGOCD_DEPLOYMENT.md)** - Comprehensive deployment guide

### **ğŸ”§ Configuration Files**
- **`helm-chart/values.yaml`** - Application configuration
- **`argocd/application.yaml`** - ArgoCD application definition
- **`.github/workflows/helm-argocd-deploy.yml`** - CI/CD pipeline

### **ğŸ“‹ Prerequisites**
- Kubernetes cluster (v1.24+)
- kubectl, helm, argocd CLI tools
- Docker for building images
- Container registry access

### **ğŸ“š Additional Documentation**
- **ğŸ“– Comprehensive Documentation**: [COMPREHENSIVE_DOCUMENTATION.md](COMPREHENSIVE_DOCUMENTATION.md)

---

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [License.md](License.md) file for details.

---

## ğŸ™ **Acknowledgments**

- FastAPI community for the excellent framework
- Kubernetes community for container orchestration
- ArgoCD team for GitOps capabilities
- Docker community for containerization
- All contributors and supporters

---

**ğŸš€ Happy Deploying!**
